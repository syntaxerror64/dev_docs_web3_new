{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Tool - Интерактивный инструмент для работы с RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот Jupyter Notebook предоставляет интерактивный инструмент для работы с Retrieval-Augmented Generation (RAG). Он позволяет загружать документы, создавать векторные базы данных, выполнять поиск релевантных документов и генерировать ответы с использованием больших языковых моделей (LLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import pickle\n",
    "\n",
    "# Загрузка переменных окружения\n",
    "load_dotenv()\n",
    "\n",
    "# Инициализация LLM и Embeddings\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Путь к файлу с документацией\n",
    "DOC_PATH = \"llms_full.txt\"\n",
    "VECTORSTORE_PATH = \"sklearn_vectorstore.parquet\"\n",
    "\n",
    "def load_documents(file_path):\n",
    "    \"\"\"Загружает документы из текстового файла.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Путь к текстовому файлу.\n",
    "\n",
    "    Returns:\n",
    "        list: Список загруженных документов.\n",
    "    \"\"\"\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"Разбивает документы на более мелкие чанки.\n",
    "\n",
    "    Args:\n",
    "        documents (list): Список документов.\n",
    "\n",
    "    Returns:\n",
    "        list: Список разбитых документов.\n",
    "    \"\"\"\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "def create_vectorstore(docs, vectorstore_path):\n",
    "    \"\"\"Создает и сохраняет векторную базу данных.\n",
    "\n",
    "    Args:\n",
    "        docs (list): Список документов для индексации.\n",
    "        vectorstore_path (str): Путь для сохранения векторной базы данных.\n",
    "\n",
    "    Returns:\n",
    "        SKLearnVectorStore: Созданная векторная база данных.\n",
    "    \"\"\"\n",
    "    vectorstore = SKLearnVectorStore.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        persist_path=vectorstore_path,\n",
    "    )\n",
    "    return vectorstore\n",
    "\n",
    "def load_vectorstore(vectorstore_path):\n",
    "    \"\"\"Загружает существующую векторную базу данных.\n",
    "\n",
    "    Args:\n",
    "        vectorstore_path (str): Путь к файлу векторной базы данных.\n",
    "\n",
    "    Returns:\n",
    "        SKLearnVectorStore: Загруженная векторная база данных.\n",
    "    \"\"\"\n",
    "    if os.path.exists(vectorstore_path):\n",
    "        vectorstore = SKLearnVectorStore(embedding=embeddings, persist_path=vectorstore_path)\n",
    "        return vectorstore\n",
    "    return None\n",
    "\n",
    "def get_qa_chain(vectorstore):\n",
    "    \"\"\"Создает цепочку RetrievalQA.\n",
    "\n",
    "    Args:\n",
    "        vectorstore (SKLearnVectorStore): Векторная база данных.\n",
    "\n",
    "    Returns:\n",
    "        RetrievalQA: Цепочка RetrievalQA.\n",
    "    \"\"\"\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever()\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "# Основной процесс\n",
    "if __name__ == \"__main__\":\n",
    "    documents = load_documents(DOC_PATH)\n",
    "    docs = split_documents(documents)\n",
    "\n",
    "    vectorstore = load_vectorstore(VECTORSTORE_PATH)\n",
    "    if not vectorstore:\n",
    "        vectorstore = create_vectorstore(docs, VECTORSTORE_PATH)\n",
    "\n",
    "    qa_chain = get_qa_chain(vectorstore)\n",
    "\n",
    "    query = \"Что такое LLM?\"\n",
    "    response = qa_chain.invoke({\"query\": query})\n",
    "    print(f\"Вопрос: {query}\")\n",
    "    print(f\"Ответ: {response[\"result\"]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}